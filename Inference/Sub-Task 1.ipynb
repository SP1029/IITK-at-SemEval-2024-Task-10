{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Sub-Task 1 Inference"]},{"cell_type":"markdown","metadata":{},"source":["### Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.545631Z","iopub.status.busy":"2024-01-26T17:55:39.545227Z","iopub.status.idle":"2024-01-26T17:55:39.551605Z","shell.execute_reply":"2024-01-26T17:55:39.550574Z","shell.execute_reply.started":"2024-01-26T17:55:39.545599Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils import data\n","\n","import dill\n","import pickle\n","import tqdm\n","import types"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.004792,"end_time":"2023-11-02T16:16:25.538502","exception":false,"start_time":"2023-11-02T16:16:25.53371","status":"completed"},"tags":[]},"source":["### Testing Pickles"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.553921Z","iopub.status.busy":"2024-01-26T17:55:39.553454Z","iopub.status.idle":"2024-01-26T17:55:39.576116Z","shell.execute_reply":"2024-01-26T17:55:39.575264Z","shell.execute_reply.started":"2024-01-26T17:55:39.553895Z"},"papermill":{"duration":0.110009,"end_time":"2023-11-02T16:16:29.027023","exception":false,"start_time":"2023-11-02T16:16:28.917014","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["pickle_folder_path = \"../Pickles/Task 1/\"\n","\n","\n","def load_erc():\n","    with open(pickle_folder_path + \"idx2utt.pickle\", \"rb\") as f:\n","        idx2utt = pickle.load(f)\n","    with open(pickle_folder_path + \"utt2idx.pickle\", \"rb\") as f:\n","        utt2idx = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"idx2emo.pickle\", \"rb\") as f:\n","        idx2emo = pickle.load(f)\n","    with open(pickle_folder_path + \"emo2idx.pickle\", \"rb\") as f:\n","        emo2idx = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"idx2speaker.pickle\", \"rb\") as f:\n","        idx2speaker = pickle.load(f)\n","    with open(pickle_folder_path + \"speaker2idx.pickle\", \"rb\") as f:\n","        speaker2idx = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"weight_matrix.pickle\", \"rb\") as f:\n","        weight_matrix = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"train_data.pickle\", \"rb\") as f:\n","        my_dataset_train = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"test_data.pickle\", \"rb\") as f:\n","        my_dataset_test = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"final_speaker_info.pickle\", \"rb\") as f:\n","        final_speaker_info = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"final_speaker_dialogues.pickle\", \"rb\") as f:\n","        final_speaker_dialogues = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"final_speaker_emotions.pickle\", \"rb\") as f:\n","        final_speaker_emotions = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"final_speaker_indices.pickle\", \"rb\") as f:\n","        final_speaker_indices = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"final_utt_len.pickle\", \"rb\") as f:\n","        final_utt_len = pickle.load(f)\n","\n","    return idx2utt, utt2idx, idx2emo, emo2idx, idx2speaker, \\\n","        speaker2idx, weight_matrix, my_dataset_train, my_dataset_test, \\\n","        final_speaker_info, final_speaker_dialogues, final_speaker_emotions, \\\n","        final_speaker_indices, final_utt_len"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["idx2utt, utt2idx, idx2emo, emo2idx, idx2speaker, \\\n","    speaker2idx, weight_matrix, my_dataset_train, my_dataset_test, \\\n","    final_speaker_info, final_speaker_dialogues, final_speaker_emotions, \\\n","    final_speaker_indices, final_utt_len = load_erc()"]},{"cell_type":"markdown","metadata":{},"source":["### Layer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_emb_layer(weights_matrix, utt2idx):\n","    num_embeddings, embedding_dim = weights_matrix.size()\n","    emb_layer = nn.Embedding(\n","        num_embeddings, embedding_dim, padding_idx=utt2idx[\"<pad>\"])\n","    emb_layer.load_state_dict({'weight': weights_matrix})\n","    emb_layer.weight.requires_grad = False\n","    return emb_layer, num_embeddings, embedding_dim"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.004285,"end_time":"2023-11-02T16:16:29.166421","exception":false,"start_time":"2023-11-02T16:16:29.162136","status":"completed"},"tags":[]},"source":["### Number of True Sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.577519Z","iopub.status.busy":"2024-01-26T17:55:39.577237Z","iopub.status.idle":"2024-01-26T17:55:39.592398Z","shell.execute_reply":"2024-01-26T17:55:39.591510Z","shell.execute_reply.started":"2024-01-26T17:55:39.577495Z"},"trusted":true},"outputs":[],"source":["def get_num_sen(fsi):\n","    true_len = 0\n","    for x in fsi.items():\n","        true_len += len(x[1])\n","    return true_len"]},{"cell_type":"markdown","metadata":{},"source":["### Function to get one-hot speaker representation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["top_speaker_names = [\"maya\", \"indu\", \"sahil\",\n","                     \"monisha\", \"rosesh\", \"madhusudhan\"]\n","NUM_SPK = len(top_speaker_names)\n","\n","\n","def get_spk_embedding(spk_original_ix):\n","    name = idx2speaker[spk_original_ix]\n","    if name in top_speaker_names:\n","        vec = torch.nn.functional.one_hot(torch.tensor(\n","            top_speaker_names.index(name), device=device), num_classes=NUM_SPK)\n","    else:\n","        vec = torch.zeros(NUM_SPK, device=device)\n","    return vec"]},{"cell_type":"markdown","metadata":{},"source":["### Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.668175Z","iopub.status.busy":"2024-01-26T17:55:39.667795Z","iopub.status.idle":"2024-01-26T17:55:39.694635Z","shell.execute_reply":"2024-01-26T17:55:39.693461Z","shell.execute_reply.started":"2024-01-26T17:55:39.668144Z"},"papermill":{"duration":0.282318,"end_time":"2023-11-02T20:12:06.617592","exception":false,"start_time":"2023-11-02T20:12:06.335274","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","def inference(model):\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        # Storing ans\n","        ans = []\n","\n","        data_loader = data_iter_test\n","\n","        for i_batch, sample_batched in tqdm.tqdm(enumerate(data_loader), total=len(data_loader)):\n","            dialogue_ids = sample_batched[0].tolist()\n","            dialogue_ids = [train_cnt+d for d in dialogue_ids]\n","            inputs = sample_batched[1]\n","            targets1 = sample_batched[2]\n","\n","            _, outputs = model(dialogue_ids, final_speaker_info, final_speaker_dialogues,\n","                               final_speaker_emotions, final_speaker_indices, inputs, mode=\"valid\")\n","\n","            for b in range(outputs.size()[0]):\n","\n","                # True length\n","                alpha = get_num_sen(final_speaker_indices[dialogue_ids[b]])\n","                beta = final_utt_len[dialogue_ids[b]]\n","                if alpha > beta:\n","                    for i in range(alpha-beta):\n","                        ans.append(\"neutral\")\n","\n","                for s in range(final_utt_len[dialogue_ids[b]]):\n","                    pred1 = torch.unsqueeze(outputs[b][s], dim=0).to(device)\n","                    pred_emo = torch.argmax(F.softmax(pred1, -1), -1).to(device)\n","\n","                    # Upadting ans\n","                    if alpha > beta:\n","                        ans.append(idx2emo[pred_emo.item()])\n","                    else:\n","                        ans.append(idx2emo[pred_emo.item()])\n","\n","        return ans"]},{"cell_type":"markdown","metadata":{},"source":["### For creating answer.txt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Line numbers of each task in the txt file\n","\n","IX1_BEGIN = 0\n","IX1_END = 1579\n","IX2_BEGIN = 1580\n","IX2_END = 9269\n","IX3_BEGIN = 9270\n","IX3_END = 17911"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.697310Z","iopub.status.busy":"2024-01-26T17:55:39.696944Z","iopub.status.idle":"2024-01-26T17:55:39.707305Z","shell.execute_reply":"2024-01-26T17:55:39.706332Z","shell.execute_reply.started":"2024-01-26T17:55:39.697277Z"},"trusted":true},"outputs":[],"source":["def ans_to_txt(ans, file_name):\n","    f = open(file_name, 'w+')\n","\n","    # MaSaC - ERC\n","    for i in range(IX1_BEGIN, IX1_END+1):\n","        label = ans[i-IX1_BEGIN]\n","        f.write(str(label)+\"\\n\")\n","\n","    # MaSaC - EFR\n","    for i in range(IX2_BEGIN, IX2_END+1):\n","        f.write(\"0.0\\n\")\n","\n","    # MELD - EFR    \n","    for i in range(IX3_BEGIN, IX3_END+1):\n","        f.write(\"0.0\\n\")\n","\n","    print(len(ans))\n","    f.close()"]},{"cell_type":"markdown","metadata":{},"source":["### Updating Weight Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = 'cpu'\n","\n","utt_ix_set = set()\n","n = len(weight_matrix)\n","d = len(weight_matrix[1])\n","\n","weight_matrix = weight_matrix.to(device)\n","new_weight_matrix = torch.zeros([n, d+NUM_SPK], device=device)\n","for ix1, sample in enumerate(my_dataset_train):\n","    for ix2, utt_ix in enumerate(sample[1]):\n","        ix_u = int(utt_ix)\n","        spk_ix = final_speaker_info[ix1][ix2]\n","        new_weight_matrix[ix_u] = torch.cat(\n","            [weight_matrix[ix_u].to(device), get_spk_embedding(spk_ix)])\n","        utt_ix_set.add(ix_u)\n","\n","for ix1, sample in enumerate(my_dataset_test):\n","    for ix2, utt_ix in enumerate(sample[1]):\n","        ix_u = int(utt_ix)\n","        spk_ix = final_speaker_info[ix1][ix2]\n","        new_weight_matrix[ix_u] = torch.cat(\n","            [weight_matrix[ix_u], get_spk_embedding(spk_ix)])\n","        utt_ix_set.add(ix_u)\n","\n","weight_matrix = new_weight_matrix"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.721472Z","iopub.status.busy":"2024-01-26T17:55:39.720838Z","iopub.status.idle":"2024-01-26T17:56:56.561571Z","shell.execute_reply":"2024-01-26T17:56:56.560576Z","shell.execute_reply.started":"2024-01-26T17:55:39.721438Z"},"trusted":true},"outputs":[],"source":["# Loading test data\n","batch_size = 8\n","data_iter_test = data.DataLoader(my_dataset_test, batch_size=batch_size, shuffle=False)\n","train_cnt = len(my_dataset_train)"]},{"cell_type":"markdown","metadata":{},"source":["### Inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def forward_test(self, chat_ids, speaker_info, sp_dialogues, sp_ind, inputs):\n","        whole_dialogue_indices = inputs\n","        \n","        bert_embs = self.embedding(whole_dialogue_indices)\n","               \n","        dialogue, h1 = self.rnnD(bert_embs)\n","        dialogue = self.drop1(dialogue)\n","\n","        device = inputs.device\n","        \n","        fop = torch.zeros((dialogue.size()[0],dialogue.size()[1],dialogue.size()[2])).to(device)\n","        fop2 = torch.zeros((dialogue.size()[0],dialogue.size()[1],dialogue.size()[2]*3)).to(device)\n","        op = torch.zeros((dialogue.size()[0],dialogue.size()[1],dialogue.size()[2])).to(device)\n","        spop = torch.zeros((dialogue.size()[0],dialogue.size()[1],dialogue.size()[2]*2)).to(device)\n","               \n","        #################### Modified for testing ############################\n","        \n","        h0 = (0.5 * torch.ones(1, 1, self.hidden_size*2)).to(device)\n","        d_h = (0.5 * torch.ones(1, 1, self.hidden_size)).to(device)\n","        attn_h = (0.5 * torch.ones(1, 1, self.hidden_size)).to(device)\n","        \n","        ######################################################################\n","        \n","        for b in range(dialogue.size()[0]):\n","            d_id = chat_ids[b]\n","            speaker_hidden_states = {}\n","            for s in range(dialogue.size()[1]):\n","                fop = op.clone()\n","                \n","                current_utt = dialogue[b][s]\n","                \n","                current_speaker = speaker_info[d_id][s]\n","                \n","                if current_speaker not in speaker_hidden_states:\n","                    speaker_hidden_states[current_speaker] = h0\n","                \n","                h = speaker_hidden_states[current_speaker]\n","                current_utt_emb = torch.unsqueeze(torch.unsqueeze(current_utt,0),0)\n","                \n","                key = fop[b][:s+1].clone()\n","                key = torch.unsqueeze(key,0)\n","                \n","                if s == 0:\n","                    tmp = torch.cat([attn_h,current_utt_emb],-1).to(device)\n","                    spop[b][s], h_new = self.rnnS(tmp,h)\n","                else:\n","                    query = current_utt_emb\n","                    attn_op,_ = self.attn(key,query)\n","                    \n","                    tmp = torch.cat([attn_op,current_utt_emb],-1).to(device)\n","                    spop[b][s], h_new = self.rnnS(tmp,h)\n","                \n","                spop[b][s] = spop[b][s].add(tmp)      \n","                speaker_hidden_states[current_speaker] = h_new\n","                \n","                fop2[b][s] = torch.cat([spop[b][s],dialogue[b][s]],-1)\n","                tmp = torch.unsqueeze(torch.unsqueeze(fop2[b][s].clone(),0),0)\n","                op[b][s],d_h = self.rnnG(tmp,d_h)\n","\n","        return op,spop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_path = \"../Models/model-task1\"\n","file_name = \"answer1.txt\"\n","\n","with open(model_path, \"rb\") as dill_file:\n","    model = dill.load(dill_file)\n","\n","model.ia.embedding, num_embeddings, embedding_dim = create_emb_layer(weight_matrix, utt2idx)\n","model.ia.forward = types.MethodType(forward_test, model.ia)\n","try:\n","    model = model.to('cpu')\n","    ans = inference(model)\n","    ans_to_txt(ans, file_name)\n","\n","except:\n","    print(\"Error\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4296024,"sourceId":7390236,"sourceType":"datasetVersion"},{"datasetId":4308760,"sourceId":7408375,"sourceType":"datasetVersion"},{"datasetId":4308785,"sourceId":7408410,"sourceType":"datasetVersion"},{"datasetId":4309024,"sourceId":7408745,"sourceType":"datasetVersion"},{"datasetId":4322051,"sourceId":7427586,"sourceType":"datasetVersion"},{"datasetId":4359003,"sourceId":7487265,"sourceType":"datasetVersion"},{"datasetId":4357565,"sourceId":7485199,"sourceType":"datasetVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
