{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Sub-Task 2 Inference"]},{"cell_type":"markdown","metadata":{},"source":["### Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.545631Z","iopub.status.busy":"2024-01-26T17:55:39.545227Z","iopub.status.idle":"2024-01-26T17:55:39.551605Z","shell.execute_reply":"2024-01-26T17:55:39.550574Z","shell.execute_reply.started":"2024-01-26T17:55:39.545599Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils import data\n","torch.set_default_device('cuda')\n","\n","import tqdm\n","import dill\n","import math\n","import pickle"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.004792,"end_time":"2023-11-02T16:16:25.538502","exception":false,"start_time":"2023-11-02T16:16:25.53371","status":"completed"},"tags":[]},"source":["### Testing Pickles"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.553921Z","iopub.status.busy":"2024-01-26T17:55:39.553454Z","iopub.status.idle":"2024-01-26T17:55:39.576116Z","shell.execute_reply":"2024-01-26T17:55:39.575264Z","shell.execute_reply.started":"2024-01-26T17:55:39.553895Z"},"papermill":{"duration":0.110009,"end_time":"2023-11-02T16:16:29.027023","exception":false,"start_time":"2023-11-02T16:16:28.917014","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["pickle_folder_path = \"../Pickles/Task 2/\"\n","\n","\n","def load_efr():\n","    with open(pickle_folder_path + \"idx2utt.pickle\", \"rb\") as f:\n","        idx2utt = pickle.load(f)\n","    with open(pickle_folder_path + \"utt2idx.pickle\", \"rb\") as f:\n","        utt2idx = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"idx2emo.pickle\", \"rb\") as f:\n","        idx2emo = pickle.load(f)\n","    with open(pickle_folder_path + \"emo2idx.pickle\", \"rb\") as f:\n","        emo2idx = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"idx2speaker.pickle\", \"rb\") as f:\n","        idx2speaker = pickle.load(f)\n","    with open(pickle_folder_path + \"speaker2idx.pickle\", \"rb\") as f:\n","        speaker2idx = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"weight_matrix.pickle\", \"rb\") as f:\n","        weight_matrix = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"train_data_trig.pickle\", \"rb\") as f:\n","        my_dataset_train = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"test_data_trig.pickle\", \"rb\") as f:\n","        my_dataset_test = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"global_speaker_info_trig.pickle\", \"rb\") as f:\n","        global_speaker_info = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"speaker_dialogues_trig.pickle\", \"rb\") as f:\n","        speaker_dialogues = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"speaker_emotions_trig.pickle\", \"rb\") as f:\n","        speaker_emotions = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"speaker_indices_trig.pickle\", \"rb\") as f:\n","        speaker_indices = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"utt_len_trig.pickle\", \"rb\") as f:\n","        utt_len = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"global_speaker_info_test_trig.pickle\", \"rb\") as f:\n","        global_speaker_info_test = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"speaker_dialogues_test_trig.pickle\", \"rb\") as f:\n","        speaker_dialogues_test = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"speaker_emotions_test_trig.pickle\", \"rb\") as f:\n","        speaker_emotions_test = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"speaker_indices_test_trig.pickle\", \"rb\") as f:\n","        speaker_indices_test = pickle.load(f)\n","\n","    with open(pickle_folder_path + \"utt_len_test_trig.pickle\", \"rb\") as f:\n","        utt_len_test = pickle.load(f)\n","\n","    return idx2utt, utt2idx, idx2emo, emo2idx, idx2speaker, \\\n","        speaker2idx, weight_matrix, my_dataset_train, my_dataset_test, \\\n","        global_speaker_info, speaker_dialogues, speaker_emotions, \\\n","        speaker_indices, utt_len, global_speaker_info_test, speaker_dialogues_test, \\\n","        speaker_emotions_test, speaker_indices_test, utt_len_test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.594308Z","iopub.status.busy":"2024-01-26T17:55:39.594010Z","iopub.status.idle":"2024-01-26T17:55:39.642978Z","shell.execute_reply":"2024-01-26T17:55:39.642133Z","shell.execute_reply.started":"2024-01-26T17:55:39.594283Z"},"trusted":true},"outputs":[],"source":["idx2utt, utt2idx, idx2emo, emo2idx, idx2speaker,\\\n","        speaker2idx, weight_matrix, my_dataset_train, my_dataset_test,\\\n","        global_speaker_info, speaker_dialogues, speaker_emotions, \\\n","        speaker_indices, utt_len_train, global_speaker_info_test, speaker_dialogues_test, \\\n","        speaker_emotions_test, speaker_indices_test, utt_len_test = load_efr()"]},{"cell_type":"markdown","metadata":{},"source":["### Layer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_emb_layer(weights_matrix, utt2idx):\n","    num_embeddings, embedding_dim = weights_matrix.size()\n","    emb_layer = nn.Embedding(\n","        num_embeddings, embedding_dim, padding_idx=utt2idx[\"<pad>\"])\n","    emb_layer.load_state_dict({'weight': weights_matrix})\n","    emb_layer.weight.requires_grad = False\n","    return emb_layer, num_embeddings, embedding_dim"]},{"cell_type":"markdown","metadata":{},"source":["### Number of True Sentences"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["PAD_SP_IX = speaker2idx[\"<pad>\"]\n","\n","\n","def get_num_sen(gsp):\n","    x = len(gsp)\n","    if x > 5:\n","        return x\n","    count = 0\n","    for ix, val in gsp.items():\n","        if val != PAD_SP_IX:\n","            count += 1\n","    return count"]},{"cell_type":"markdown","metadata":{},"source":["### Function to get one-hot speaker representation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.668175Z","iopub.status.busy":"2024-01-26T17:55:39.667795Z","iopub.status.idle":"2024-01-26T17:55:39.694635Z","shell.execute_reply":"2024-01-26T17:55:39.693461Z","shell.execute_reply.started":"2024-01-26T17:55:39.668144Z"},"papermill":{"duration":0.282318,"end_time":"2023-11-02T20:12:06.617592","exception":false,"start_time":"2023-11-02T20:12:06.335274","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["top_speaker_names = [\"maya\", \"indu\", \"sahil\", \"monisha\", \"rosesh\", \"madhusudhan\"]\n","NUM_SPK = len(top_speaker_names)\n","\n","\n","def get_spk_embedding(spk_original_ix):\n","    name = idx2speaker[spk_original_ix]\n","    if name in top_speaker_names:\n","        vec = torch.nn.functional.one_hot(torch.tensor(\n","            top_speaker_names.index(name), device=device), num_classes=NUM_SPK)\n","    else:\n","        vec = torch.zeros(NUM_SPK, device=device)\n","    return vec"]},{"cell_type":"markdown","metadata":{},"source":["### Inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def inference(model):\n","    model.eval()\n","    with torch.no_grad():\n","\n","        # Storing ans\n","        ans = []\n","\n","        data_loader = data_iter_test\n","        for i_batch, sample_batched in tqdm.tqdm(enumerate(data_loader)):\n","            dialogue_ids = sample_batched[0].tolist()\n","            inputs = sample_batched[1].to(device)\n","            emotions = sample_batched[2].to(device)\n","\n","            emo_one_hot = torch.zeros((emotions.size()[0], emotions.size()[1], 8)).to(device)\n","            \n","            for b in range(emotions.size()[0]):\n","                for s in range(emotions.size()[1]):\n","                    emo_one_hot[b][s][emotions[b][s].item()] = 1\n","\n","            # Creating the speaker_ids\n","            speaker_ids = []\n","            for d_ids_list in dialogue_ids:\n","                sp_id_list = [0] * len(d_ids_list)\n","                for ix, d_id in enumerate(d_ids_list):\n","                    sp_id = global_speaker_info[d_id][0]\n","                    sp_id_list[ix] = sp_id\n","                speaker_ids.append(sp_id_list)\n","\n","            outputs = model(inputs, emo_one_hot, dialogue_ids,speaker_ids, utt_len_test)\n","\n","            for b in range(outputs.size()[0]):\n","\n","                # True length\n","                alpha = get_num_sen(global_speaker_info_test[dialogue_ids[b][0]])\n","                beta = utt_len_test[dialogue_ids[b][0]]\n","                if alpha > beta:\n","                    for i in range(alpha-beta):\n","                        ans.append(0)\n","\n","                for s in range(utt_len_test[dialogue_ids[b][0]]):\n","                    pred2 = outputs[b][s]\n","                    pred_flip = torch.argmax(F.softmax(pred2.to(device), -1), -1)\n","\n","                    # Updating ans\n","                    if alpha > beta:\n","                        ans.append(pred_flip.item())\n","                    else:\n","                        ans.append(pred_flip.item())\n","\n","        return ans"]},{"cell_type":"markdown","metadata":{},"source":["### For creating answer.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.697310Z","iopub.status.busy":"2024-01-26T17:55:39.696944Z","iopub.status.idle":"2024-01-26T17:55:39.707305Z","shell.execute_reply":"2024-01-26T17:55:39.706332Z","shell.execute_reply.started":"2024-01-26T17:55:39.697277Z"},"trusted":true},"outputs":[],"source":["# Line numbers of each task in the txt file\n","\n","IX1_BEGIN = 0\n","IX1_END = 1579\n","IX2_BEGIN = 1580\n","IX2_END = 9269\n","IX3_BEGIN = 9270\n","IX3_END = 17911\n","\n","def ans_to_txt(ans, file_name):\n","    f = open(file_name, 'w+')\n","\n","    # MaSaC - ERC\n","    for i in range(IX1_BEGIN, IX1_END+1):\n","        f.write(\"neutral\\n\")\n","\n","    # MaSaC - EFR\n","    for i in range(IX2_BEGIN, IX2_END+1):\n","        label = ans[i-IX2_BEGIN]\n","        f.write(str(label)+\".0\\n\")\n","    \n","\n","    # MELD - EFR\n","    for i in range(IX3_BEGIN, IX3_END+1):\n","        f.write(\"0.0\\n\")\n","\n","    f.close()"]},{"cell_type":"markdown","metadata":{},"source":["### Loading model and testing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch_size = 128\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","data_iter_test = data.DataLoader(my_dataset_test, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-26T17:55:39.721472Z","iopub.status.busy":"2024-01-26T17:55:39.720838Z","iopub.status.idle":"2024-01-26T17:56:56.561571Z","shell.execute_reply":"2024-01-26T17:56:56.560576Z","shell.execute_reply.started":"2024-01-26T17:55:39.721438Z"},"trusted":true},"outputs":[],"source":["model_path = \"../Models/model-task2\"\n","file_name = \"answer2.txt\"\n","\n","with open(model_path, \"rb\") as dill_file:\n","        model = dill.load(dill_file)\n","\n","try:\n","        model.emoGRU.RNN.flatten_parameters()\n","        model.encoder, _, _ = create_emb_layer(weight_matrix,utt2idx)\n","        ans = inference(model)\n","        ans_to_txt(ans, file_name)\n","except:\n","        print(\"Error\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4296024,"sourceId":7390236,"sourceType":"datasetVersion"},{"datasetId":4308760,"sourceId":7408375,"sourceType":"datasetVersion"},{"datasetId":4308785,"sourceId":7408410,"sourceType":"datasetVersion"},{"datasetId":4309024,"sourceId":7408745,"sourceType":"datasetVersion"},{"datasetId":4322051,"sourceId":7427586,"sourceType":"datasetVersion"},{"datasetId":4359003,"sourceId":7487265,"sourceType":"datasetVersion"},{"datasetId":4357565,"sourceId":7485199,"sourceType":"datasetVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
