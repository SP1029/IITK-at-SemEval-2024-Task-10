{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to update the json by splitting the conversations into groups of size <=15\n",
    "- Update the file initials to proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Initials\n",
    "\n",
    "file_initials = \"MaSaC_train_erc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from copy import deepcopy as cpy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "GROUP_LEN = 15\n",
    "is_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read File\n",
    "\n",
    "file_name = \"./\" + file_initials + \".json\"\n",
    "with open(file_name, 'r') as file:\n",
    "    dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "\n",
    "episodes_list = []\n",
    "speakers_list = []\n",
    "utterances_list = []\n",
    "if is_test == False:\n",
    "    emotions_list = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    episodes_list.append(dataset[i]['episode'])\n",
    "    speakers_list.append(dataset[i]['speakers'])\n",
    "    utterances_list.append(dataset[i]['utterances'])\n",
    "    if is_test == False:\n",
    "        emotions_list.append(dataset[i]['emotions'])\n",
    "\n",
    "N = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new dataset\n",
    "\n",
    "new_dataset = []\n",
    "\n",
    "count = 0\n",
    "i = 0\n",
    "j = 0\n",
    "eps = 0\n",
    "\n",
    "dialogue = {}\n",
    "dialogue['episode'] = eps\n",
    "dialogue['speakers'] = []\n",
    "dialogue['utterances'] = []\n",
    "if is_test == False:\n",
    "    dialogue['emotions'] = []\n",
    "\n",
    "while i < len(dataset):\n",
    "    entry_len = len(dataset[i]['speakers'])\n",
    "\n",
    "    if count < GROUP_LEN and j != entry_len:\n",
    "        # Add record to dialogue\n",
    "        dialogue['speakers'].append(dataset[i]['speakers'][j])\n",
    "        dialogue['utterances'].append(dataset[i]['utterances'][j])\n",
    "        if is_test == False:\n",
    "            dialogue['emotions'].append(dataset[i]['emotions'][j])\n",
    "        j += 1\n",
    "        count += 1\n",
    "\n",
    "    elif j == entry_len:\n",
    "        # Add created dialogue to new dataset\n",
    "        new_dataset.append(cpy(dialogue))\n",
    "\n",
    "        # Make new\n",
    "        eps += 1\n",
    "        dialogue = {}\n",
    "        dialogue['episode'] = eps\n",
    "        dialogue['speakers'] = []\n",
    "        dialogue['utterances'] = []\n",
    "        if is_test == False:\n",
    "            dialogue['emotions'] = []\n",
    "\n",
    "        # Update vars\n",
    "        j = 0\n",
    "        i += 1\n",
    "        count = 0\n",
    "\n",
    "    else:\n",
    "        # Add created dialogue to new dataset\n",
    "        new_dataset.append(cpy(dialogue))\n",
    "\n",
    "        # Make new\n",
    "        eps += 1\n",
    "        dialogue = {}\n",
    "        dialogue['episode'] = eps\n",
    "        dialogue['speakers'] = []\n",
    "        dialogue['utterances'] = []\n",
    "        if is_test == False:\n",
    "            dialogue['emotions'] = []\n",
    "\n",
    "        # Update vars\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the new json\n",
    "\n",
    "with open(file_initials + '_new.json', 'w+') as f:\n",
    "    json.dump(new_dataset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
